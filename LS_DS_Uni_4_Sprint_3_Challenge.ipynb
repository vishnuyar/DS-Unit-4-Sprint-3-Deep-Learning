{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "# Major Neural Network Architectures Challenge\n",
    "## *Data Science Unit 4 Sprint 3 Challenge*\n",
    "\n",
    "In this sprint challenge, you'll explore some of the cutting edge of Data Science. This week we studied several famous neural network architectures: \n",
    "recurrent neural networks (RNNs), long short-term memory (LSTMs), convolutional neural networks (CNNs), and Generative Adverserial Networks (GANs). In this sprint challenge, you will revisit these models. Remember, we are testing your knowledge of these architectures not your ability to fit a model with high accuracy. \n",
    "\n",
    "__*Caution:*__  these approaches can be pretty heavy computationally. All problems were designed so that you should be able to achieve results within at most 5-10 minutes of runtime on Colab or a comparable environment. If something is running longer, doublecheck your approach!\n",
    "\n",
    "## Challenge Objectives\n",
    "*You should be able to:*\n",
    "* <a href=\"#p1\">Part 1</a>: Train a RNN classification model\n",
    "* <a href=\"#p2\">Part 2</a>: Utilize a pre-trained CNN for objective detection\n",
    "* <a href=\"#p3\">Part 3</a>: Describe the components of an autoencoder\n",
    "* <a href=\"#p4\">Part 4</a>: Describe yourself as a Data Science and elucidate your vision of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-5UwGRnJOmD4"
   },
   "source": [
    "<a id=\"p1\"></a>\n",
    "## Part 1 - RNNs\n",
    "\n",
    "Use an RNN/LSTM to fit a multi-class classification model on reuters news articles to distinguish topics of articles. The data is already encoded properly for use in an RNN model. \n",
    "\n",
    "Your Tasks: \n",
    "- Use Keras to fit a predictive model, classifying news articles into topics. \n",
    "- Report your overall score and accuracy\n",
    "\n",
    "For reference, the [Keras IMDB sentiment classification example](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py) will be useful, as well the RNN code we used in class.\n",
    "\n",
    "__*Note:*__  Focus on getting a running model, not on maxing accuracy with extreme data size or epoch numbers. Only revisit and push accuracy if you get everything else done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1114
    },
    "colab_type": "code",
    "id": "DS-9ksWjoJit",
    "outputId": "0c3512e4-5cd4-4dc6-9cda-baf00c835f59"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "import numpy as np\n",
    "# save np.load\n",
    "np_load_old = np.load\n",
    "\n",
    "# modify the default parameters of np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None,\n",
    "                                                         skip_top=0,\n",
    "                                                         maxlen=None,\n",
    "                                                         test_split=0.2,\n",
    "                                                         seed=723812,\n",
    "                                                         start_char=1,\n",
    "                                                         oov_char=2,\n",
    "                                                         index_from=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fLKqFh8DovaN",
    "outputId": "64b0d621-7e74-4181-9116-406e8c518465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iran is encoded as 779 in the data\n",
      "London is encoded as 544 in the data\n",
      "Words are encoded as numbers in our dataset.\n"
     ]
    }
   ],
   "source": [
    "# Demo of encoding\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "print(f\"Iran is encoded as {word_index['iran']} in the data\")\n",
    "print(f\"London is encoded as {word_index['london']} in the data\")\n",
    "print(\"Words are encoded as numbers in our dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_QVSlFEAqWJM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 train sequences\n",
      "2246 test sequences\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (8982, 200)\n",
      "X_test shape: (2246, 200)\n",
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "batch_size = 46\n",
    "max_features = len(word_index.values())\n",
    "maxlen = 200\n",
    "\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')\n",
    "\n",
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "\n",
    "print('Build model...')\n",
    "# TODO - your code!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((8982, 46), (2246, 46))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting y data to multi array\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1115 18:02:18.433508 139797932513088 deprecation.py:506] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W1115 18:02:18.455321 139797932513088 deprecation.py:506] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#### Build model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,200))\n",
    "model.add(LSTM(200, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1115 18:02:25.081766 139797932513088 deprecation.py:323] From /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 8982 samples, validate on 2246 samples\n",
      "8970/8982 [============================>.] - ETA: 0s - loss: 2.2300 - acc: 0.4193"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[9,116] = 30979 is not in [0, 30979)\n\t [[{{node embedding/embedding_lookup}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7e6689446504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m           validation_data=(X_test, y_test))\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m score, acc = model.evaluate(X_test, y_test,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    410\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[9,116] = 30979 is not in [0, 30979)\n\t [[{{node embedding/embedding_lookup}}]]"
     ]
    }
   ],
   "source": [
    "# You should only run this cell once your model has been properly configured\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          validation_data=(X_test, y_test))\n",
    "\n",
    "score, acc = model.evaluate(X_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence Data Question\n",
    "#### *Describe the `pad_sequences` method used on the training dataset. What does it do? Why do you need it?*\n",
    "\n",
    "While training any data, the Keras model expects a standar input size. For RNN which is used for NLP, most of the natural lanuage is in various shape of sentences and words, some sentences might be long and some words might be bigger than others. In such cases it is imperative that we standardise these sentences and words. Padding is used to standardised these inputs. We take the longest word or the sentence in the given input and then transform the other inputs with having the same number of word length or sentence length. All that extra words length or sentence length is filled with empty spaces. This process is called padding.\n",
    "\n",
    "## RNNs versus LSTMs\n",
    "#### *What are the primary motivations behind using Long-ShortTerm Memory Cell unit over traditional Recurrent Neural Networks?*\n",
    "\n",
    "Recurrent Neural Networks sometime have the disadvantage of vanishing or exploding values in the memory cells due to which sometimes training over the RNN might result in less accuracy, LSTM overcomes this advantages by having forget and remember gate which try to minimise such errors.\n",
    "\n",
    "\n",
    "\n",
    "## RNN / LSTM Use Cases\n",
    "#### *Name and Describe 3 Use Cases of LSTMs or RNNs and why they are suited to that use case*\n",
    "\n",
    "RNN are used when simple text processing is done such as classfication of topics\n",
    "LSTM are used when trying to create a more dense outputs such as predicting the next sequences of sentences or the translations of lanuage from one language to another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yz0LCZd_O4IG"
   },
   "source": [
    "<a id=\"p2\"></a>\n",
    "## Part 2- CNNs\n",
    "\n",
    "### Find the Frog\n",
    "\n",
    "Time to play \"find the frog!\" Use Keras and ResNet50 (pre-trained) to detect which of the following images contain frogs:\n",
    "\n",
    "<img align=\"left\" src=\"https://d3i6fh83elv35t.cloudfront.net/newshour/app/uploads/2017/03/GettyImages-654745934-1024x687.jpg\" width=400>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "whIqEWR236Af",
    "outputId": "7a74e30d-310d-4a3a-9ae4-5bf52d137bda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google_images_download in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (2.8.0)\n",
      "Requirement already satisfied: selenium in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from google_images_download) (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from selenium->google_images_download) (1.23)\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install google_images_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 332
    },
    "colab_type": "code",
    "id": "EKnnnM8k38sN",
    "outputId": "59f477e9-0b25-4a38-9678-af24e0176535"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = lilly frog pond\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "Image URL: https://image.shutterstock.com/image-photo/green-frogs-pond-lilly-pads-260nw-50197960.jpg\n",
      "Completed Image ====> 1.green-frogs-pond-lilly-pads-260nw-50197960.jpg\n",
      "Image URL: https://thumbs.dreamstime.com/z/smiling-frog-lily-pad-pond-993691.jpg\n",
      "Completed Image ====> 2.smiling-frog-lily-pad-pond-993691.jpg\n",
      "Image URL: https://img-aws.ehowcdn.com/350x235p/photos.demandstudios.com/getty/article/110/213/78036715_XS.jpg\n",
      "Completed Image ====> 3.78036715_XS.jpg\n",
      "Image URL: https://i.pinimg.com/originals/b8/16/5b/b8165b6914cd2b65d8a0effd619c7c33.jpg\n",
      "Completed Image ====> 4.b8165b6914cd2b65d8a0effd619c7c33.jpg\n",
      "Image URL: https://previews.123rf.com/images/lffile/lffile0909/lffile090900006/5570627-small-frog-on-a-lily-pad-in-a-pond-with-a-blooming-pink-lily-.jpg\n",
      "Completed Image ====> 5.5570627-small-frog-on-a-lily-pad-in-a-pond-with-a-blooming-pink-lily-.jpg\n",
      "\n",
      "Errors: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from google_images_download import google_images_download\n",
    "\n",
    "response = google_images_download.googleimagesdownload()\n",
    "arguments = {\"keywords\": \"lilly frog pond\", \"limit\": 5, \"print_urls\": True}\n",
    "absolute_image_paths = response.download(arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "si5YfNqS50QU"
   },
   "source": [
    "At time of writing at least a few do, but since the Internet changes - it is possible your 5 won't. You can easily verify yourself, and (once you have working code) increase the number of images you pull to be more sure of getting a frog. Your goal is to validly run ResNet50 on the input images - don't worry about tuning or improving the model.\n",
    "\n",
    "*Hint* - ResNet 50 doesn't just return \"frog\". The three labels it has for frogs are: `bullfrog, tree frog, tailed frog`\n",
    "\n",
    "*Stretch goals* \n",
    "- Check for fish or other labels\n",
    "- Create a matplotlib visualizations of the images and your prediction as the visualization label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaT07ddW3nHz"
   },
   "outputs": [],
   "source": [
    "# You've got something to do in this cell. ;)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def process_img_path(img_path):\n",
    "  return image.load_img(img_path, target_size=(224, 224))\n",
    "\n",
    "def img_contains_frog(img):\n",
    "    \"\"\" Scans image for Frogs\n",
    "    \n",
    "    Should return a boolean (True/False) if a frog is in the image.\n",
    "    \n",
    "    Inputs:\n",
    "    ---------\n",
    "    img:  Precrossed image ready for prediction. The `process_img_path`             function should already be applied to the image. \n",
    "    \n",
    "    Returns: \n",
    "    ---------\n",
    "    frogs (boolean):  TRUE or FALSE - There are frogs in the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    model = ResNet50(weights='imagenet')\n",
    "    features = model.predict(x)\n",
    "    results = decode_predictions(features, top=5)[0]\n",
    "    print(results)\n",
    "    for entry in results:\n",
    "        if 'frog' in ent[1]:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "image/jpeg": {
       "width": 600
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='./downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg', width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'downloads/lilly frog pond'\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot identify image file 'downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-e67304acf9eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_contains_frog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_img_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{file} contains Frog in the image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-b06c019341e0>\u001b[0m in \u001b[0;36mprocess_img_path\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_img_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimg_contains_frog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2620\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2622\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file 'downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    if (file[-3:]=='jpg'):\n",
    "        filepath = path+'/'+file\n",
    "        if (img_contains_frog(process_img_path(filepath))):\n",
    "            print(f'{file} contains Frog in the image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot identify image file './downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-e5b175af83b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess_img_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-2c7bfde5cf24>\u001b[0m in \u001b[0;36mprocess_img_path\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_img_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimg_contains_frog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2620\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2622\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file './downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'"
     ]
    }
   ],
   "source": [
    "process_img_path('./downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot identify image file './downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d01ecbb37475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_contains_frog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_img_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-2c7bfde5cf24>\u001b[0m in \u001b[0;36mprocess_img_path\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprocess_img_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimg_contains_frog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2620\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2622\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file './downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'"
     ]
    }
   ],
   "source": [
    "img_contains_frog(process_img_path('./downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry = [('n07753592', 'bull frog', 0.06412259),('n03532672', 'hook', 0.06004637), ('n03498962', 'hatchet', 0.058439817)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image contains frog\n",
      "image does not contain frog\n",
      "image does not contain frog\n"
     ]
    }
   ],
   "source": [
    "for ent in entry:\n",
    "    if 'frog' in ent[1]:\n",
    "        print('image contains frog')\n",
    "    else:\n",
    "        print('image does not contain frog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot identify image file './downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-b29439bfc245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    108\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    109\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'L'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2620\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2621\u001b[0m     raise IOError(\"cannot identify image file %r\"\n\u001b[0;32m-> 2622\u001b[0;31m                   % (filename if filename else fp))\n\u001b[0m\u001b[1;32m   2623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2624\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot identify image file './downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg'"
     ]
    }
   ],
   "source": [
    "load_img('./downloads/lilly frog pond/1.green-frogs-pond-lilly-pads-260nw-50197960.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/DS-Unit-4-Sprint-3-Deep-Learning\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stretch Goal: Displaying Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XEuhvSu7O5Rf"
   },
   "source": [
    "<a id=\"p3\"></a>\n",
    "## Part 3 - Autoencoders\n",
    "\n",
    "Describe a use case for an autoencoder given that an autoencoder tries to predict its own input. \n",
    "\n",
    "__*Your Answer:*__ \n",
    "\n",
    "Autoencoder can be used to remove noise from the inputs. For example if an image contains noise, we can use autoencoders to remove the noise and restore it with the required image.\n",
    "\n",
    "Autoencoders can also be used for similarity testing such that if we want to see a particular face from a series of images, we can use the original image to encode into a lower dimension vector. and then use the lower dimension vector to compare against the lower dimension vectors of the faces given to us.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "626zYgjkO7Vq"
   },
   "source": [
    "<a id=\"p4\"></a>\n",
    "## Part 4 - More..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "__lDWfcUO8oo"
   },
   "source": [
    "Answer the following questions, with a target audience of a fellow Data Scientist:\n",
    "\n",
    "- What do you consider your strongest area, as a Data Scientist?\n",
    "\n",
    "As a Data Scientist, my strongest area is Data Analysis\n",
    "\n",
    "- What area of Data Science would you most like to learn more about, and why?\n",
    "\n",
    "I would like to know more about Unsupervised learning, as I believe that the future for Artifical Intelligence lies in the area of Unsupervised learning.\n",
    "\n",
    "- Where do you think Data Science will be in 5 years?\n",
    "\n",
    "Data Science will continue to evolve both in terms of more efficient algorithms and also evolve in the area of research in the Artificial Intelligence\n",
    "\n",
    "- What are the threats posed by AI to our society?\n",
    "\n",
    "AI can continue to explode on the bias which has been implemented in the socient, as AI learns from past data, our past data is filled with discriminatory bias and the AI will learn the same and continue to perpetuate the bias.\n",
    "- How do you think we can counteract those threats? \n",
    "\n",
    "We can conteract these kind of threats by continue to monitor the bias and to input changes in to the AI system such that the bias over the time minimised in the system.\n",
    "\n",
    "- Do you think achieving General Artifical Intelligence is ever possible?\n",
    "\n",
    "Yes, General AI is possible, only because we as humans have known about it and we are trying to achieve it, historically, whenever science or science fiction talks about a pehenomenon it is eventually realised as awareness is the first step to achievement.\n",
    "\n",
    "A few sentences per answer is fine - only elaborate if time allows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Hoqe3mM_Mtc"
   },
   "source": [
    "## Congratulations! \n",
    "\n",
    "Thank you for your hard work, and congratulations! You've learned a lot, and you should proudly call yourself a Data Scientist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"<iframe src=\"https://giphy.com/embed/26xivLqkv86uJzqWk\" width=\"480\" height=\"270\" frameBorder=\"0\" class=\"giphy-embed\" allowFullScreen></iframe><p><a href=\"https://giphy.com/gifs/mumm-champagne-saber-26xivLqkv86uJzqWk\">via GIPHY</a></p>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_Unit_4_Sprint_Challenge_4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "u4-s3-dnn"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
